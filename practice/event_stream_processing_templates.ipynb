{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422a3d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "from json import JSONDecodeError\n",
    "\n",
    "CHUNK = 10 * 1024   # 10 KB\n",
    "\n",
    "\n",
    "def process_log_lines(path: str) -> int:\n",
    "    \"\"\"\n",
    "    Count how many lines in the file contain the substring 'ERROR'.\n",
    "    Lines are separated by '\\n'.\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    buffer = \"\"\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        while chunk := f.read(CHUNK):\n",
    "            buffer += chunk\n",
    "            parts = buffer.split(\"\\n\")\n",
    "            # all but last are full lines\n",
    "            for line in parts[:-1]:\n",
    "                if \"ERROR\" in line:\n",
    "                    count += 1\n",
    "            buffer = parts[-1]\n",
    "    # handle final partial line\n",
    "    if buffer and \"ERROR\" in buffer:\n",
    "        count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def process_ndjson(path: str, field: str = \"value\") -> int:\n",
    "    \"\"\"\n",
    "    Sum the given field across every JSON object in an NDJSON file\n",
    "    (one JSON object per line).\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    buffer = \"\"\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        while chunk := f.read(CHUNK):\n",
    "            buffer += chunk\n",
    "            lines = buffer.split(\"\\n\")\n",
    "            for raw in lines[:-1]:\n",
    "                obj = json.loads(raw)\n",
    "                total += obj.get(field, 0)\n",
    "            buffer = lines[-1]\n",
    "    # last line if it wasnâ€™t newline-terminated\n",
    "    if buffer.strip():\n",
    "        obj = json.loads(buffer)\n",
    "        total += obj.get(field, 0)\n",
    "    return total\n",
    "\n",
    "\n",
    "def process_concat_json(path: str) -> Counter:\n",
    "    \"\"\"\n",
    "    Read a file of back-to-back JSON objects (no delimiters)\n",
    "    and count occurrences of each obj['type'].\n",
    "    \"\"\"\n",
    "    counts: Counter = Counter()\n",
    "    buffer = \"\"\n",
    "    decoder = json.JSONDecoder()\n",
    "\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        while chunk := f.read(CHUNK):\n",
    "            buffer += chunk\n",
    "            while True:\n",
    "                try:\n",
    "                    obj, idx = decoder.raw_decode(buffer)\n",
    "                except JSONDecodeError:\n",
    "                    break\n",
    "                counts[obj.get(\"type\", \"<missing>\")] += 1\n",
    "                buffer = buffer[idx:]\n",
    "\n",
    "    # any trailing complete object?\n",
    "    while buffer:\n",
    "        try:\n",
    "            obj, idx = decoder.raw_decode(buffer)\n",
    "        except JSONDecodeError:\n",
    "            break\n",
    "        counts[obj.get(\"type\", \"<missing>\")] += 1\n",
    "        buffer = buffer[idx:]\n",
    "\n",
    "    return counts\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
